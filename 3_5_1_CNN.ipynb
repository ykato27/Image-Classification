{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-5-1_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykato27/Image-Classification/blob/main/3_5_1_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMT_xLvDja-H"
      },
      "source": [
        "# 畳み込みニューラルネットワークの実装 \n",
        "# Implementation of convolutional neural networks\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSsECCjN9m9t"
      },
      "source": [
        "#### 最適化法のクラスの読み込み Loading a class of optimization methods\n",
        "\n",
        "これまでと同じです．下のコードが隠されたセルも実行してください．\n",
        "\n",
        "「コードを表示」を選んで1行目の ` #@title` を消去するとコードの全体が表示されます．\n",
        "\n",
        "The same as before. Run the cell with the hidden code below.\n",
        "\n",
        "Select \"Show Code\" and delete the ` #@title` in the first line to show the whole code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BoIW9rC9j3D"
      },
      "source": [
        "#@title\n",
        "class SGD:\n",
        "  def __init__(self, learning_rate = 0.01):\n",
        "    self.lr = learning_rate\n",
        "\n",
        "  def update(self, params, grads):\n",
        "    for key in params:\n",
        "      params[key] -= self.lr * grads[key] \n",
        "\n",
        "class Momentum:\n",
        "  def __init__(self, learning_rate = 0.01, alpha = 0.5):\n",
        "    '''\n",
        "    self.lr = learning_rate : 学習係数\n",
        "    self.alpha = alpha      : alpha\n",
        "    '''\n",
        "    self.lr = learning_rate\n",
        "    self.alpha = alpha\n",
        "    self.v = None \n",
        "\n",
        "  def update(self, params, grads):\n",
        "    '''\n",
        "    params : 更新するパラメータ\n",
        "    grads  : 目的関数のパラメータに関する勾配\n",
        "    self.v : モメンタム，パラメータと同じ形式\n",
        "\n",
        "    '''\n",
        "    # self.v の初期化\n",
        "    if self.v is None:\n",
        "      self.v = {}\n",
        "      for key in params:\n",
        "        self.v[key] = np.zeros_like(params[key])\n",
        "    \n",
        "    # モメンタムとパラメータの更新\n",
        "    for key in params:\n",
        "      self.v[key] = self.alpha * self.v[key] - self.lr * grads[key] \n",
        "      params[key] += self.v[key]\n",
        "\n",
        "class Adam:\n",
        "  def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.beta1 = beta1\n",
        "    self.beta2 = beta2\n",
        "    self.iter = 0\n",
        "    self.m = None\n",
        "    self.v = None\n",
        "    \n",
        "  def update(self, params, grads):\n",
        "    if self.m is None:\n",
        "      self.m, self.v = {}, {}\n",
        "      for key in params:\n",
        "        self.m[key] = np.zeros_like(params[key])\n",
        "        self.v[key] = np.zeros_like(params[key])\n",
        "\n",
        "    self.iter += 1\n",
        "    lr_t  = self.learning_rate * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n",
        "      \n",
        "    for key in params.keys():\n",
        "      self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n",
        "      self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n",
        "      params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n",
        "\n",
        "class AdaGrad:\n",
        "  def __init__(self, learning_rate = 0.01):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.h = None\n",
        "      \n",
        "  def update(self, params, grads):\n",
        "    if self.h is None:\n",
        "      self.h = {}\n",
        "      for key in params:\n",
        "        self.h[key] = np.zeros_like(params[key])\n",
        "        \n",
        "    for key in params:\n",
        "      self.h[key] += grads[key] * grads[key]\n",
        "      params[key] -= self.learning_rate * grads[key] / (np.sqrt(self.h[key]) + 1e-7)  "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ros4u9u7A9mz"
      },
      "source": [
        "#### 既存の層の高階化対応 Support for higher order of existing layers\n",
        "\n",
        "アファイン変換層は入力が4階の配列の場合，出力が2階の配列になるように書き換えます．バッチ正規化層は入力が4階の場合，出力も4階になるように書き換えます．シグモイド層，ReLU層，ドロップアウト層はそのままで4階の場合にも対応できます．ソフトマックス層の入力は常に2階のもののみです．\n",
        "\n",
        "\n",
        "The affine transformation layer is rewritten so that when the input is a 4-level array, the output is a 2-level array. Batch normalization layer is rewritten so that when the input is a fourth-order array, the output is also a fourth-order array. The sigmoid, ReLU, and dropout layers can be rewritten to handle the fourth-order case. The softmax layer always accepts only second-order inputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iOQemqFwf3B"
      },
      "source": [
        "def softmax(a):   \n",
        "  # a がベクトルのとき\n",
        "  if a.ndim == 1:\n",
        "    c = np.max(a)#オーバーフロー対策1\n",
        "    x = a-c\n",
        "    x = 709*(x >= 709) + x*(x<709)#オーバーフロー対策2\n",
        "    exp_x = np.exp(x)\n",
        "    sum_exp_x = np.sum(exp_x)\n",
        "    return exp_x/sum_exp_x\n",
        "    \n",
        "  # a が２階の配列のとき\n",
        "  a = a.T\n",
        "  c = np.max(a, axis=0) #オーバーフロー対策1\n",
        "  x = a - c\n",
        "  x = 709*(x >= 709) + x*(x<709) #オーバーフロー対策2\n",
        "  exp_x = np.exp(x)\n",
        "  sum_exp_x = np.sum(exp_x, axis=0)\n",
        "  return (exp_x/sum_exp_x).T\n",
        "\n",
        "def sigmoid(x):\n",
        "  x = -709*(x <= -709)+709*(x >= 709) + x*(x>-709) *(x<709) #オーバーフロー対策\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "\n",
        "class Affine:\n",
        "  def __init__(self, W, b):\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "    self.x = None\n",
        "    self.dW = None\n",
        "    self.db = None\n",
        "    self.xshpe = None\n",
        "    \n",
        "  def forward(self, x):\n",
        "    #2階の配列に直す\n",
        "    self.xshape = x.shape\n",
        "    x = x.reshape(self.xshape[0],-1)\n",
        "    \n",
        "    self.x = x\n",
        "    out = np.dot(self.x, self.W) +self.b\n",
        "    return out\n",
        "  \n",
        "  def backward(self,dout):\n",
        "    self.dW = np.dot(self.x.T, dout)\n",
        "    self.db = np.sum(dout, axis=0)\n",
        "    dx = np.dot(dout, self.W.T)\n",
        "    \n",
        "    #元の形に戻す\n",
        "    dx = dx.reshape(*self.xshape)# *はカッコを外す \n",
        "    return dx\n",
        "  \n",
        "class Relu:       ####Relu層の定義\n",
        "  def __init__(self):\n",
        "    self.mask = None\n",
        "    \n",
        "  def forward(self, x):\n",
        "    self.mask = (x > 0)  # x> 0 ならTrue , x<= 0 ならFalse\n",
        "    out = x * self.mask  # x> 0 なら x * 1  , x<= 0 なら x * 0\n",
        "    return out\n",
        "  \n",
        "  def backward(self,dout):\n",
        "    dx = dout * self.mask\n",
        "    return dx\n",
        "\n",
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.y = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.y = sigmoid(x)\n",
        "    return self.y\n",
        "  \n",
        "  def backward(self,dout):\n",
        "    dx = dout*(1-self.y)*self.y\n",
        "    return dx\n",
        "\n",
        "  \n",
        "class SoftmaxWithLoss:\n",
        "  def __self__(self):\n",
        "    self.loss = None\n",
        "    self.y = None\n",
        "    self.t = None\n",
        "    \n",
        "  def forward(self, x, t):\n",
        "    y = softmax(x)\n",
        "    self.y = y\n",
        "    self.t = t\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(t*np.log(y+1e-7))/batch_size   # 1e-7 = 10^(-7)はlogの中に0を入力するのを防止するため\n",
        "  \n",
        "  def backward(self):\n",
        "    batch_size = self.y.shape[0]\n",
        "    dx = (self.y-self.t)/batch_size\n",
        "    return dx\n",
        "  \n",
        "class BatchNormalization:\n",
        "  def __init__(self, gamma = 1, beta = 0, momentum=0.9, running_mean=None, running_var=None):    \n",
        "    self.beta = beta\n",
        "    self.gamma = gamma\n",
        "    self.momentum = momentum\n",
        "    \n",
        "    # テスト時に使用する平均と分散\n",
        "    self.running_mean = running_mean\n",
        "    self.running_var = running_var\n",
        "   \n",
        "    self.std = None\n",
        "    self.xc = None\n",
        "    self.y = None\n",
        "    self.xshape = None\n",
        "  \n",
        "  def forward(self, x, train_flag = True):\n",
        "    \n",
        "    #2階の配列に直す\n",
        "    self.xshape = x.shape\n",
        "    x = x.reshape(self.xshape[0], -1)\n",
        "    \n",
        "    \n",
        "    if self.running_mean is None:\n",
        "      D = x.shape[1]\n",
        "      self.running_mean = np.zeros(D)\n",
        "      self.running_var = np.zeros(D)\n",
        "    \n",
        "    if train_flag:\n",
        "      mu = np.mean(x, axis=0)  #バッチについての平均．\n",
        "      var = np.mean((x-mu)**2, axis=0) \n",
        "      std = np.sqrt(var+10e-7)     \n",
        "      xc = (x-mu)/std    \n",
        "      y = self.gamma * xc + self.beta\n",
        "      \n",
        "      self.std = std\n",
        "      self.xc = xc\n",
        "      \n",
        "      self.running_mean = self.momentum * self.running_mean + (1-self.momentum) * mu\n",
        "      self.running_var = self.momentum * self.running_var + (1-self.momentum) * var  \n",
        "      \n",
        "    else:\n",
        "      xc = (x - self.running_mean) / (np.sqrt(self.running_var + 10e-7)) \n",
        "      y = self.gamma * xc + self.beta\n",
        "      \n",
        "    #yをxの元の形と同じ形にする\n",
        "    y = y.reshape(*self.xshape)\n",
        "    return y      \n",
        "  \n",
        "  def backward(self, dout):\n",
        "    #2階の配列に直す\n",
        "    dout = dout.reshape(self.xshape[0], -1)\n",
        "    \n",
        "    \n",
        "    self.dbeta = dout.sum(axis = 0) \n",
        "    self.dgamma = (self.xc * dout).sum(axis = 0)\n",
        "    c = np.mean(dout, axis=0)\n",
        "    d = np.mean(self.xc * dout, axis =0)\n",
        "    dx = dout - c - self.xc * d\n",
        "    dx *= self.gamma/self.std\n",
        "    \n",
        "    #dxをxの元の形と同じ形にする\n",
        "    dx = dx.reshape(*self.xshape)\n",
        "    return dx\n",
        "\n",
        "class Dropout:\n",
        "  def __init__(self, dropout_ratio = 0.5):\n",
        "    self.dropout_ratio = dropout_ratio\n",
        "    self.mask = None\n",
        "  \n",
        "  def forward(self, x, train_flag = True):\n",
        "    if train_flag:\n",
        "      self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
        "      return x * self.mask\n",
        "    else:\n",
        "      return x * (1.0 - self.dropout_ratio)\n",
        "  \n",
        "  def backward(self, dout):\n",
        "    return dout * self.mask\n",
        "    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9FUPVz-9_yv"
      },
      "source": [
        "畳み込み層とプーリング層の読み込み\n",
        "\n",
        "Loading convolution and pooling layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6SKrJ9--GtV"
      },
      "source": [
        "class Convolution:\n",
        "  def __init__(self, F, b, stride=1, pad=0):\n",
        "    self.F = F\n",
        "    self.b = b\n",
        "    self.stride = stride\n",
        "    self.pad = pad\n",
        "        \n",
        "    #中間データ（backward時に使用）\n",
        "    self.xshape = None   \n",
        "    self.xh = None\n",
        "    self.f_col = None\n",
        "        \n",
        "    # 勾配\n",
        "    self.dF = None\n",
        "    self.db = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    OC, C, FH, FW = self.F.shape\n",
        "    N, C, H, W = x.shape\n",
        "    pad = self.pad\n",
        "    stride = self.stride\n",
        "    \n",
        "    #出力サイズ\n",
        "    OH = (H + 2 * pad - FH)//stride +1\n",
        "    OW = (W + 2 * pad - FW)//stride +1\n",
        "    \n",
        "    # xh, xt, xcol の順に計算\n",
        "    x_pad = np.pad(x, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')# (N,C,H,W)のうち最後の2つの方向に関してパディングする \n",
        "    xh = np.zeros((N, C, FH, FW, OH, OW))\n",
        "    for fh in range(FH):\n",
        "      for fw in range(FW):\n",
        "        xh[:,:,fh,fw,:,:] =x_pad[:,:,fh:fh + OH * stride:stride, fw: fw + OW * stride:stride] \n",
        "    xt = xh.transpose(0,4,5,1,2,3) # (N, OH, OW, C, FH, FW)\n",
        "    xcol = xt.reshape(N,OH,OW,-1)  # (N, OH, OW,  C * FH * FW)\n",
        "    \n",
        "    #出力 y を計算\n",
        "    fcol = self.F.reshape(OC,-1).T # (C * FH * FW, OC)\n",
        "    y = (np.dot(xcol,fcol) + self.b).transpose(0,3,1,2)  #  (N, OH, OW, OC).transpose(0,3,1,2) = (N, OC, OH, OW)\n",
        "    \n",
        "    #クラス変数として格納\n",
        "    self.xshape = x.shape   \n",
        "    self.xh = xh\n",
        "    self.fcol = fcol\n",
        "     \n",
        "    return y\n",
        "    \n",
        "  def backward(self,dout):\n",
        "    OC, C, FH, FW = self.F.shape\n",
        "    N, OC, OH, OW = dout.shape\n",
        "    N, C, H, W = self.xshape\n",
        "    stride = self.stride\n",
        "    pad = self.pad\n",
        "    \n",
        "    # db と dF を計算\n",
        "    xh_col = self.xh.transpose(1,2,3,0,4,5).reshape(C,FH,FW,-1) # (C, FH, FW, N, OH, OW).reshape(C,FH,FW,-1) = (C, FH, FW, N * OH * OW)\n",
        "    dout_col = dout.transpose(1,0,2,3).reshape(OC,-1) # (OC, N * OH * OW)\n",
        "    self.db = dout_col.sum(axis = 1) # (OC,)\n",
        "    self.dF = np.dot(dout_col, xh_col.transpose(0,1,3,2)) # (OC, N * OH * OW)(C, FH, N * OH * OW,  FW) = (OC, C, FH, FW)\n",
        "    \n",
        "    # dout と F から dxt を計算\n",
        "    dxt = np.dot(dout.transpose(0,2,3,1), self.F.transpose(1,2,0,3))# (N, OH, OW, OC)( C, FH, OC, FW) = (N, OH, OW, C, FH, FW)\n",
        "    dxt = dxt.transpose(0,3,1,2,4,5) #(N, OH, OW, C, FH, FW)\n",
        "        \n",
        "    #  dxt から dx を計算\n",
        "    dx = np.zeros((N, C, H+ 2*pad + stride - 1, W+ 2*pad + stride - 1), dtype=np.float)  \n",
        "    for fh in range(FH):\n",
        "      for fw in range(FW):\n",
        "        dx[:,:,fh:fh + OH * stride: stride, fw: fw + OW * stride: stride] += dxt[:,:,:, :,fh,fw]\n",
        "    \n",
        "    return dx[:, :, pad:H+pad, pad:W+pad] \n",
        "      \n",
        "class Pooling:\n",
        "  def __init__(self, S):\n",
        "    self.S = S\n",
        "        \n",
        "    #中間データ（backward時に使用）\n",
        "    self.xshape = None   \n",
        "    self.argmax = None\n",
        " \n",
        "  def forward(self, x):\n",
        "    N, C, H, W = x.shape\n",
        "    S = self.S\n",
        "    FH, FW = S, S #本来は必要ないがコードを書く際に混乱するので導入\n",
        "    stride = S\n",
        "    self.xshape = x.shape\n",
        "    \n",
        "    #出力サイズ\n",
        "    OH = H//S\n",
        "    OW = W//S\n",
        "    \n",
        "    # xh, xt, xcol の順に計算    \n",
        "    xh = np.zeros((N, C, FH, FW, OH, OW))\n",
        "    for fh in range(FH):\n",
        "      for fw in range(FW):\n",
        "        xh[:,:,fh,fw,:,:] =x[:,:,fh:fh + OH * stride:stride, fw: fw + OW * stride:stride] \n",
        "    xt = xh.transpose(0,1,4,5,2,3) # (N, C, OH, OW, FH, FW)\n",
        "    xcol = xt.reshape(N, C, OH,OW, -1)  # (N, C, OH, OW,  FH * FW)\n",
        "    \n",
        "    #argmaxを格納\n",
        "    self.argmax = xcol.argmax(axis = -1).flatten()\n",
        " \n",
        "   \n",
        "    #出力 y を計算\n",
        "    y = xcol.max(axis = 4)  # (N, C, OH, OW)\n",
        "    return y\n",
        "    \n",
        "  def backward(self,dout):\n",
        "    N, C, OH, OW = dout.shape\n",
        "    N, C, H, W = self.xshape\n",
        "    S = self.S\n",
        "    FH, FW = S, S #本来は必要ないがコードを書く際に混乱するので導入\n",
        "    stride = S\n",
        "   \n",
        "    # dout と　self.argmax から dxt を計算\n",
        "    dxt = np.zeros((N * C * OH * OW, FH * FW))\n",
        "    dxt[np.arange(N * C * OH * OW), self.argmax] = dout.flatten() # (N * C * OH *OW, FH*FW) =  (N * C * OH * OW)\n",
        "    dxt = dxt.reshape(N, C, OH, OW, FH, FW) \n",
        "        \n",
        "    #  dxt から dx を計算\n",
        "    dx = np.zeros((N, C, H+ stride - 1, W+ stride - 1), dtype=np.float)  \n",
        "    for fh in range(FH):\n",
        "      for fw in range(FW):\n",
        "        dx[:,:,fh:fh + OH * stride: stride, fw: fw + OW * stride: stride] += dxt[:,:,:, :,fh,fw]\n",
        "    \n",
        "    return dx[:, :, :H, :W]  \n",
        "      "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ7nHw8wPWoy"
      },
      "source": [
        "#### ネットワーククラス Network Class\n",
        "\n",
        "新しいネットワークのクラスである` CNN` では前章の `MultiLayerNet`　に  `convolution()` というメソッドを追加して，`self.conlolution()` を実行するたびに畳み込み層が追加できるようにします．\n",
        "\n",
        "コンストラクタのパラメータ：\n",
        "\n",
        "*   `weight_decay_lambda`：ウェイト減衰法（$W_i$の大きさを減衰させる）のパラメータ（デフォルトは 0.0）\n",
        "\n",
        "affine() のパラメータ：\n",
        "\n",
        "*   `size`：層のサイズ （デフォルトは `None`）\n",
        "*   `activation`：`'relu'` か `'sigmoid'` か `None`  \n",
        "*   `batchnorm = False`：活性化関数の前にバッチ正規化するかどうか．\n",
        "\n",
        "dropout() のパラメータ：\n",
        "\n",
        "*   `dropout_ratio = 0.5`：ドロップアウトでマスクされる確率（デフォルトは 0.5）\n",
        "\n",
        "convolution() のパラメータ：\n",
        "\n",
        "*  `OC, FH, FW`：フィルターの出力チャンネル数，高さ，幅\n",
        "* `stride=1, pad=0`：ストライド，パディングの幅\n",
        "*   `batchnorm = False`：活性化関数の前にバッチ正規化するかどうか．\n",
        "*   `activation = None`：`'relu'` か `'sigmoid'`（デフォルトは `None`）\n",
        "*  `S=1`：プーリングの正方形のフィルターのサイズ．`S=1` のときはプーリングは行わない．\n",
        "\n",
        "畳み込み層における細かく分けた層の順番は Convolution -- BatchNormalization -- Activation -- Pooling の順\n",
        "\n",
        "For our new network class `CNN`, we will add a method `convolution()` to `MultiLayerNet` from the previous chapter so that we can add a convolution layer each time we run `self.convolution()`.\n",
        "\n",
        "Constructor parameters:.\n",
        "\n",
        "* `weight_decay_lambda`: parameter for weight decay method (to decay the size of $W_i$) (default is 0.0)\n",
        "\n",
        "Parameters for affine():\n",
        "\n",
        "* `size`: size of the layer (default is `None`)\n",
        "* `activation`: `'relu'` or `'sigmoid'` or `None`.  \n",
        "* `batchnorm = False`: whether to batch normalize before the activation function.\n",
        "\n",
        "Parameters for dropout():.\n",
        "\n",
        "* `dropout_ratio = 0.5`: probability of being masked by dropout (default is 0.5).\n",
        "\n",
        "Parameters for convolution(): \n",
        "\n",
        "* `OC, FH, FW`: number of output channels, height and width of the filter.\n",
        "* `stride=1, pad=0`: stride, width of padding.\n",
        "* `batchnorm = False`: whether to batch normalize before the activation function.\n",
        "* `activation = None`: `'relu'` or `'sigmoid'` (default is `None`)\n",
        "* `S=1`: Size of the pooling square filter. If `S=1`, no pooling is done.\n",
        "\n",
        "The order of the layers in the convolutional layer is Convolution -- BatchNormalization -- Activation -- Pooling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YikRRSHh7Au9"
      },
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "class CNN:\n",
        "  '''\n",
        "    コンストラクタの引数\n",
        "    input_size          : 入力データ一つの次元\n",
        "    weight_decay_lambda : L2正則化の係数\n",
        "\n",
        "    クラス変数\n",
        "    self.layers      : 層を格納する順序付き辞書\n",
        "                       活性化関数も独立した層として扱う\n",
        "    self.params      : 重みパラメータを格納する辞書\n",
        "                       W1,W2 などと番号が付くのはAffine層の重みのみ \n",
        "    '''\n",
        "  def __init__(self, input_dim = (1,28,28),  weight_decay_lambda = 0.0):\n",
        "    self.all_dim_list = [input_dim] #各層を流れるデータの形を格納\n",
        "    self.params = {}\n",
        "    self.weight_decay_lambda = weight_decay_lambda\n",
        "    self.layers = OrderedDict()\n",
        "    self.batchnorm_flag = [False]\n",
        "    self.lastLayer = SoftmaxWithLoss()\n",
        "    self.idx = 0\n",
        "    \n",
        "  #層の追加  \n",
        "  '''\n",
        "  affine 層を付け加える場合は，\n",
        "  self.affine(size = 100, activation = 'relu', batchnorm = True) \n",
        "  とすると，層のサイズ100，活性化関数ReLU, バッチ正規化ありになる\n",
        "  self.affine(100, activation = 'sigmoid')\n",
        "  とすると，層のサイズ100，活性化関数Sigmoid, バッチ正規化なし\n",
        "    \n",
        "  dropout 層を付け加える場合は\n",
        "  self.dropout(dropout_ratio = 0.6)\n",
        "  とするとマスクされる確率が0.6\n",
        "  self.dropout()\n",
        "  とするとマスクされる確率が0.5\n",
        "  \n",
        "  畳み込み層の追加： \n",
        "  convolution(self, OC＝10, FH=3, FW=3, stride = 1, pad = 0, S = 2, activation = 'relu', batchnorm = False)\n",
        "  とすると stride = 1，pad = 0，プーリングのサイズ2，活性化ReLU，バッチ正規化なし\n",
        "  convolution(self, OC＝10, FH=3, FW=3)\n",
        "  とすると stride = 1，pad = 0，S = 1 つまりプーリングなし，活性化なし，バッチ正規化なし\n",
        "  '''\n",
        "  \n",
        "  #アファイン層を追加するメソッド\n",
        "  def affine(self, size, activation='relu',  batchnorm = False):\n",
        "    self.idx += 1\n",
        "    idx = self.idx    \n",
        "    self.all_dim_list.append(size)\n",
        "    \n",
        "    # Heの初期値によるパラメータの初期化\n",
        "    scale = np.sqrt(2.0 / np.prod(self.all_dim_list[idx - 1]))\n",
        "    self.params['W' + str(idx)] = scale * np.random.randn(np.prod(self.all_dim_list[idx-1]), size)\n",
        "    self.params['b' + str(idx)] = np.zeros(size)\n",
        "    \n",
        "    #アファイン層の追加\n",
        "    self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)], self.params['b' + str(idx)])\n",
        "    \n",
        "    #バッチ正規化層の追加\n",
        "    if batchnorm:\n",
        "      self.batchnorm_flag.append(True)\n",
        "      self.params['gamma' + str(idx)] = np.ones(size)\n",
        "      self.params['beta' + str(idx)] = np.zeros(size)\n",
        "      self.layers['BatchNorm' + str(idx)] = BatchNormalization(self.params['gamma' + str(idx)], \n",
        "                                                                       self.params['beta' + str(idx)])\n",
        "    else:\n",
        "      self.batchnorm_flag.append(False)\n",
        "    \n",
        "    #活性化層の追加\n",
        "    if activation == 'relu':\n",
        "      self.layers['Relu' + str(idx)] = Relu()\n",
        "    if activation == 'sigmoid':\n",
        "      self.layers['Sigmoid' + str(idx)] = Sigmoid()\n",
        "  \n",
        "  #ドロップアウト層をの追加するメソッド    \n",
        "  def dropout(self, dropout_ratio = 0.5):\n",
        "    self.layers['Dropout' + str(self.idx)] = Dropout(dropout_ratio)      \n",
        "  \n",
        "  #畳み込み層を追加するメソッド\n",
        "  def convolution(self, OC, FH, FW, stride = 1, pad = 0, S = 2, activation=None, batchnorm = False):\n",
        "    self.idx += 1\n",
        "    idx = self.idx\n",
        "    C, H, W =  self.all_dim_list[idx - 1]    \n",
        "    \n",
        "    #出力サイズ\n",
        "    OH = (H + 2 * pad - FH)//stride +1 # //は切り捨て除算\n",
        "    OW = (W + 2 * pad - FW)//stride +1\n",
        "    \n",
        "    # パラメータの初期化（Heの初期値）\n",
        "    scale = np.sqrt(2.0 / (C*FH*FW))\n",
        "    self.params['F' + str(idx)] = scale * np.random.randn(OC, C, FH, FW)\n",
        "    self.params['b' + str(idx)] = np.zeros(OC)\n",
        "    \n",
        "    #畳み込み層の追加\n",
        "    self.layers['Conv' + str(idx)] = Convolution(self.params['F' + str(idx)], self.params['b' + str(idx)], \n",
        "                                                        stride = stride, pad = pad)          \n",
        "    #バッチ正規化層の追加\n",
        "    if batchnorm:\n",
        "      self.batchnorm_flag.append(True)\n",
        "      self.params['gamma' + str(idx)] = np.ones(OC*OH*OW)\n",
        "      self.params['beta' + str(idx)] = np.zeros(OC*OH*OW)\n",
        "      self.layers['BatchNorm' + str(idx)] = BatchNormalization(self.params['gamma' + str(idx)], \n",
        "                                                                       self.params['beta' + str(idx)])\n",
        "    else:\n",
        "      self.batchnorm_flag.append(False)\n",
        "    \n",
        "    #活性化層の追加\n",
        "    if activation == 'relu':\n",
        "      self.layers['Relu' + str(idx)] = Relu()\n",
        "    if activation == 'sigmoid':\n",
        "      self.layers['Sigmoid' + str(idx)] = Sigmoid()\n",
        "    \n",
        "    #プーリング層の追加\n",
        "    if S > 1:\n",
        "      self.layers['Pooling' + str(idx)] = Pooling(S)\n",
        "      OH = OH//S\n",
        "      OW = OW//S\n",
        "      \n",
        "    #出力サイズの格納\n",
        "    self.all_dim_list.append((OC,OH,OW))\n",
        "    \n",
        "  \n",
        "  #順方向の計算 #Softmaxの手前まで\n",
        "  def predict(self, x, train_flg=False):\n",
        "    for key, layer in self.layers.items():\n",
        "      if \"Dropout\" in key or \"BatchNorm\" in key:\n",
        "        x = layer.forward(x, train_flg)\n",
        "      else:\n",
        "        x = layer.forward(x)\n",
        "    return x\n",
        "  \n",
        "  #誤差の計算\n",
        "  def loss(self,x,t, train_flg=False):\n",
        "    x = self.predict(x, train_flg)\n",
        "    return self.lastLayer.forward(x ,t)\n",
        "  \n",
        "  #精度（クラッシュ対策でバッチに分割して計算）\n",
        "  def accuracy(self, x, t, batch_size=100):\n",
        "    acc = 0.0\n",
        "    for i in range(int(x.shape[0] / batch_size)):\n",
        "      tx = x[i*batch_size:(i+1)*batch_size]\n",
        "      tt = t[i*batch_size:(i+1)*batch_size]\n",
        "      y = self.predict(tx, train_flg=False)\n",
        "      y = np.argmax(y, axis=1)\n",
        "      tt = np.argmax(tt, axis=1)\n",
        "      acc += np.sum(y == tt)\n",
        "\n",
        "    return acc / x.shape[0]\n",
        "  \n",
        "  #誤差逆伝搬法による勾配の計算\n",
        "  def gradient(self,x,t):\n",
        "    self.loss(x,t,train_flg = True)\n",
        "    \n",
        "    dout = self.lastLayer.backward()\n",
        "    \n",
        "    layers = list(self.layers.values())\n",
        "    layers.reverse()\n",
        "    for layer in layers:\n",
        "      dout = layer.backward(dout)\n",
        "    \n",
        "    #出力辞書の生成\n",
        "    grads = {}\n",
        "    all_num = len(self.all_dim_list)\n",
        "    \n",
        "    for idx in range(1, all_num):\n",
        "      #アファイン層か畳み込み層かで場合分けして勾配をgradsに追加\n",
        "      if type(self.all_dim_list[idx]) == int:#アファインのときはデータの型は整数型\n",
        "        grads['W' + str(idx)] = self.layers['Affine' + str(idx)].dW+ self.weight_decay_lambda * self.params['W' + str(idx)]\n",
        "        grads['b' + str(idx)] = self.layers['Affine' + str(idx)].db\n",
        "      else:#アファインのときはデータの型はtuple\n",
        "        grads['F' + str(idx)] = self.layers['Conv' + str(idx)].dF+ self.weight_decay_lambda * self.params['F' + str(idx)]\n",
        "        grads['b' + str(idx)] = self.layers['Conv' + str(idx)].db\n",
        "      \n",
        "      #正規化層の勾配をgradsに追加\n",
        "      if self.batchnorm_flag[idx]:\n",
        "        grads['gamma' + str(idx)] = self.layers['BatchNorm' + str(idx)].dgamma\n",
        "        grads['beta' + str(idx)] = self.layers['BatchNorm' + str(idx)].dbeta\n",
        "    \n",
        "    return grads\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5A6ziXobTL2"
      },
      "source": [
        "学習を行う関数の読み込み Loading the function for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhb4A-NnbRPX",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#学習用の関数\n",
        "def training(network, x_train, t_train,  x_test, t_test, iters_num=10000,  batch_size=100):\n",
        "  '''\n",
        "  この関数を使う前に optimizer を与えておく必要がある\n",
        "  例：\n",
        "  optimizer = SGD(learning_rate = 0.01)\n",
        "  '''\n",
        "  network.train_accuracy_list =[] \n",
        "  network.test_accuracy_list =[] \n",
        "  train_size = x_train.shape[0]\n",
        "\n",
        "  for i in range(iters_num):\n",
        "    if i%int(iters_num/10) ==0:\n",
        "      #精度の記録 \n",
        "      choice = np.random.choice(len(x_train),len(x_test))\n",
        "      x_train_part, t_train_part = x_train[choice], t_train[choice]\n",
        "      train_accuracy = network.accuracy(x_train_part,t_train_part)\n",
        "      test_accuracy = network.accuracy(x_test,t_test)\n",
        "      network.train_accuracy_list.append(train_accuracy)\n",
        "      network.test_accuracy_list.append(test_accuracy)\n",
        "      print('iteration:', i, ' train_accuracy = ', train_accuracy,\n",
        "            ' test_accuracy = ', test_accuracy)\n",
        "\n",
        "    #ミニバッチを選ぶ  \n",
        "    batch_mask = np.random.choice(train_size,batch_size, replace=False)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    #勾配を計算  \n",
        "    grads = network.gradient(x_batch,t_batch)     \n",
        "\n",
        "    # パラメータを更新 \n",
        "    optimizer.update(network.params, grads)\n",
        "\n",
        "  #精度の記録  \n",
        "  choice = np.random.choice(len(x_test),len(x_test))\n",
        "  x_train_part, t_train_part = x_train[choice], t_train[choice]\n",
        "  train_accuracy = network.accuracy(x_train_part,t_train_part)\n",
        "  test_accuracy = network.accuracy(x_test,t_test)\n",
        "  network.train_accuracy_list.append(train_accuracy)\n",
        "  network.test_accuracy_list.append(test_accuracy)\n",
        "  print('iteration:', i, ' train_accuracy = ', train_accuracy,\n",
        "        ' test_accuracy = ', test_accuracy)\n",
        "      "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N0LMOWyQYCq"
      },
      "source": [
        "### 7.3.2 MNISTデータセットで実験 Experimenting with the MNIST Dataset\n",
        "\n",
        "それではCNNを動かして実験してみましょう．\n",
        "\n",
        "MNISTデータセットの読み込みなどは前節と同じです．\n",
        "\n",
        "Now let's run the experiment with a CNN.\n",
        "\n",
        "Loading the MNIST dataset is the same as in the previous section.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zorG4ynnQYCs",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "train = np.loadtxt('/content/sample_data/mnist_train_small.csv',  # 読み込みたいファイルのパス\\\n",
        "                  dtype = 'int',  # 出力される配列の要素のデータ型\\\n",
        "                  delimiter= ',',    # ファイルの区切り文字 \\\n",
        "                  #skiprows= 0,      # 先頭の何行を無視するか（指定した行数までは読み込まない）\\\n",
        "                  #usecols=None  # 読み込みたい列番号 \\\n",
        "                 )\n",
        "test = np.loadtxt('/content/sample_data/mnist_test.csv', \\\n",
        "                  dtype = 'int',  delimiter= ',')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQqwEpRJ2WED"
      },
      "source": [
        "入力データセットは $\\mbox{(データ数)}\\times 1\\times 28\\times 28$ と4階の配列に直します．入力データのチャンネル数は1です．\n",
        "\n",
        "The input dataset is rewritten as a 4-level array as $\\mbox{(number of data)}\\times 1\\times 28\\times 28$. The number of input data channels is 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZRaqy6FQYCv"
      },
      "source": [
        "train_size = train.shape[0]\n",
        "x_train = train.T[1:].T/float(255)\n",
        "x_train = x_train.reshape(train_size,1,28,28)\n",
        "t_train =  np.eye(10)[train.T[0]]\n",
        "test_size = test.shape[0]\n",
        "x_test = test.T[1:].T/float(255)\n",
        "x_test = x_test.reshape(test_size,1,28,28)\n",
        "t_test =  np.eye(10)[test.T[0]]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyDI8MSrQzwX"
      },
      "source": [
        "####  単純なCNN,  A simple CNN\n",
        "\n",
        "```\n",
        "入力 - conv - relu - pool - affine - relu - affine - softmax\n",
        "```\n",
        "\n",
        "という比較的簡単な CNN を定義してみましょう．\n",
        "\n",
        "始めの畳み込み層のパラメータは，OC = 30, FH = 5, FW =5, S = 2 ととります．\n",
        "\n",
        "Let's define a relatively simple CNN as above.\n",
        "\n",
        "The parameters of the first convolutional layer are OC = 30, FH = 5, FW =5, S = 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuUrKKxlqzEV"
      },
      "source": [
        "network = CNN(input_dim=(1,28,28))\n",
        "network.convolution(OC = 30, FH = 5, FW =5, S = 2, activation = 'relu')\n",
        "network.affine(100)\n",
        "network.affine(10, activation = None)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtY6qkpQNnbd"
      },
      "source": [
        "出来上がったネットワークの構造は `network.layers` および\n",
        "`network.all_dim_list`  で見られます．\n",
        "\n",
        "中間層のサイズが $30\\times 12\\times 12= 4320$ と大きいことが分かります．\n",
        "\n",
        "The structure of the resulting network can be seen by \n",
        "network.layers` and `network.all_dim_list`.\n",
        "\n",
        "The size of the middle layer is large as $30\\times 12\\times 12= 4320$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM_BJO_yMrp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaee9a10-aa99-475b-d372-00c4c7fb0bdf"
      },
      "source": [
        "print(network.all_dim_list)\n",
        "network.layers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 28, 28), (30, 12, 12), 100, 10]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('Conv1', <__main__.Convolution at 0x7ff793122fd0>),\n",
              "             ('Relu1', <__main__.Relu at 0x7ff793122510>),\n",
              "             ('Pooling1', <__main__.Pooling at 0x7ff793122650>),\n",
              "             ('Affine2', <__main__.Affine at 0x7ff797867510>),\n",
              "             ('Relu2', <__main__.Relu at 0x7ff797867850>),\n",
              "             ('Affine3', <__main__.Affine at 0x7ff793122d90>)])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CormwMAPQ7jF"
      },
      "source": [
        "では実験開始です．iters_num=1000  （1000*100/20000 = 5回転 = 5エポック）としています．\n",
        "\n",
        "           はたしてどうなるでしょうか\n",
        "\n",
        "Let's start the experiment. We set iters_num=1000 (1000*100/20000 = 5 revolutions = 5 epochs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKYVwZ71rYdA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "6620d08d-a699-43ae-bb52-0508fa0e8139"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "training(network, x_train, t_train, x_test, t_test, iters_num=1000, batch_size = 100)\n",
        "\n",
        "#学習記録の表示\n",
        "x = np.arange(0,len(network.train_accuracy_list),1) \n",
        "\n",
        "#グラフが見にくくなるので初期値は表示しない\n",
        "plt.plot(x[1:], network.train_accuracy_list[1:], label = 'train_data')  \n",
        "plt.plot(x[1:], network.test_accuracy_list[1:], label = 'test_data')  \n",
        "\n",
        "plt.legend() #グラフの線の説明を表示"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0  train_accuracy =  0.0507  test_accuracy =  0.049\n",
            "iteration: 100  train_accuracy =  0.9416  test_accuracy =  0.9455\n",
            "iteration: 200  train_accuracy =  0.965  test_accuracy =  0.959\n",
            "iteration: 300  train_accuracy =  0.9737  test_accuracy =  0.9668\n",
            "iteration: 400  train_accuracy =  0.9812  test_accuracy =  0.9737\n",
            "iteration: 500  train_accuracy =  0.9867  test_accuracy =  0.9762\n",
            "iteration: 600  train_accuracy =  0.9909  test_accuracy =  0.9782\n",
            "iteration: 700  train_accuracy =  0.9916  test_accuracy =  0.9791\n",
            "iteration: 800  train_accuracy =  0.992  test_accuracy =  0.9789\n",
            "iteration: 900  train_accuracy =  0.9919  test_accuracy =  0.9799\n",
            "iteration: 999  train_accuracy =  0.9923  test_accuracy =  0.9824\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff7977fb110>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}